
  

Here is my Dataset Link : Dataset- https://www.youtube.com/watch?v=d2g9HlwoC-s

I have used this dataset for my tasks completion.
# Overview

The objective involves analyzing a given video by detecting faces, employing OCR to recognize text, and generating descriptive captions for each frame, ultimately weaving together a coherent narrative that provides insights into the video content, such as identifying the most frequent face and pinpointing timestamps for specific text instances.

# Dependencies
To successfully execute the video analysis, ensure you have the following dependencies:
Python 3.x: This analysis is implemented in Python programming language. Python 3.x is recommended for compatibility.

OpenCV (Open Source Computer Vision Library): OpenCV is a powerful open-source library used for computer vision tasks, including face detection.

Tesseract: Tesseract is an open-source OCR engine maintained by Google. It's used for text recognition in images and videos.

Pytesseract: Pytesseract is a Python wrapper for Tesseract OCR engine. It allows easy integration of Tesseract into Python applications.

Transformers: Transformers is a library released by Hugging Face that provides state-of-the-art natural language processing models. It can be used for various text-related tasks.

PIL (Python Imaging Library): PIL is a library used for opening, manipulating, and saving many different image file formats. It is commonly used for image processing tasks.

Regular Expressions (re): Regular Expressions (regex) is a powerful tool for pattern matching and text manipulation. It's often used for extracting specific information from text data.
